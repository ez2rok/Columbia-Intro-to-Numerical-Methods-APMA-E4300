{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as any collaborators you worked with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c0e6f80c9a8d85d80baddc8df3890a0",
     "grade": false,
     "grade_id": "cell-7531378247537850",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import the factorial function from scipy\n",
    "from scipy.special import factorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57fe3d1a770d32fc71d10c52d47d5765",
     "grade": false,
     "grade_id": "cell-1055125360070174",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# HW 1:  Forms of Error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "763bdcd61a173c57e8d82dcd9519ee2c",
     "grade": false,
     "grade_id": "cell-9681214437904696",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1:  definition of errors\n",
    "\n",
    "**(a)**  [4 pts] Write a short python program to calculate and return, the absolute error, relative error and degree of decimal precision (as defined in class) given an object `f` and its approximation `F`.  Note, both `f` and `F` can be numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c9bcb87e713e8ee4fb90ec822ed4d9f",
     "grade": false,
     "grade_id": "cell-a6ede65cf8ed685f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def errors(f,F):\n",
    "    \"\"\" calculate various measures of error of an object f and its approximation F\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f:  numpy.array (or float)\n",
    "        array of true values\n",
    "        \n",
    "    F: numpy.array\n",
    "        array of approximate values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    e: array of absolute errors\n",
    "    r: array of relative errors\n",
    "    p: integer array of precisions\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # compute absolute errors\n",
    "    e = numpy.abs(f - F)\n",
    "    \n",
    "    # compute relative errors\n",
    "    r = e / numpy.abs(f)\n",
    "    \n",
    "    # compute precisions\n",
    "    p = -numpy.log10(r/5.).astype(int)\n",
    "    \n",
    "    return e, r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "811e12c9907b5b3fc93463b352dff5c3",
     "grade": true,
     "grade_id": "cell-da2659b413c73ca7",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed scalar test\n",
      "passed array test\n"
     ]
    }
   ],
   "source": [
    "# test simple scalars\n",
    "e,r,p = errors(numpy.exp(1),2.72)\n",
    "answer = [0.0017181715409551046, 0.0006320799863232398, 3]\n",
    "numpy.testing.assert_allclose([e,r,p], answer)\n",
    "print('passed scalar test')\n",
    "\n",
    "# test with array input\n",
    "x = [1., 2., 3.]\n",
    "f = numpy.exp(x)\n",
    "F = [ 2.718,  7.389,  20.085]\n",
    "e,r,p = errors(f,F)\n",
    "numpy.testing.assert_allclose(e,[2.81828459e-04, 5.60989307e-05, 5.36923188e-04])\n",
    "numpy.testing.assert_allclose(r,[1.03678896e-04, 7.59216467e-06, 2.67318315e-05])\n",
    "numpy.testing.assert_allclose(p,[4, 5, 5])\n",
    "print('passed array test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90b05b8f5232214b804110a26a04be3f",
     "grade": false,
     "grade_id": "cell-bef4e3baf992ed93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(b)** [4 pts] Use your routine to calculate various errors for several rational approximations to $\\pi$\n",
    "\n",
    "* $f = \\pi$ and $F = 22 / 7$\n",
    "* $f = \\pi$ and $F = 314 / 100$\n",
    "* $f = \\pi$ and $F = 355 / 113$\n",
    "\n",
    "Compare the most precise approximation to the least precise approximation.  How many more digits of precision do you gain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3 7\n"
     ]
    }
   ],
   "source": [
    "# you can put some working code here to generate your answers, but put your answers in the cell below\n",
    "p1 = errors(numpy.pi, 22/7)[2]\n",
    "p2 = errors(numpy.pi, 314/100)[2]\n",
    "p3 = errors(numpy.pi, 355/113)[2]\n",
    "print(p1, p2, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9ac9462caae1146fa324fe338dd0c1d",
     "grade": true,
     "grade_id": "cell-4300360216304258",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$ \\text{We gain } 4 \\text{ digits of precision}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9680d17c5d494ccba620eb525f2ae882",
     "grade": false,
     "grade_id": "cell-23707a8e710ca676",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(c)** [4 pts] $F = n \\log(n) - n$ is Stirling's approximation to  $f = \\log(n!)$ for large values of $n$. \n",
    "Do the following\n",
    "\n",
    "* Make a plot showing the relative error and degree of decimal precision for $f$ and $F$ as a function of integer $n$\n",
    "\n",
    "* Estimate the smallest value of $n$ where Stirling's approximation is good to 4 decimal places of precision.  \n",
    "\n",
    "**Note**: If you use the `factorial` function imported from `scipy.special`, you will not be able to answer this question.  **Why?**  \n",
    "\n",
    "**Hint**: However there is another way to evaluate $\\log(n!)$ for integer $n$ that will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stirling_approximatation(n):\n",
    "    \"\"\"\"\n",
    "    return n log(n) - n, which is Stirling's approximation of log(n!) for large values of n\n",
    "    \"\"\"\n",
    "    \n",
    "    return n * numpy.log(n) - n   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_n_factorial(n):\n",
    "    \"\"\"\n",
    "    compute log(n!)\n",
    "    \"\"\"\n",
    "    \n",
    "    x = numpy.arange(2, n+1)\n",
    "    return numpy.sum([numpy.log(val) for val in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_approximation(n_values, relative_errors, precision_errors, n_val):\n",
    "    \"\"\"\n",
    "    plot the relative error and precision of stirling's approximation as n increases\n",
    "    n_val is the value of n we want to highlight\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.title(\"Relative Error & Precision of Stirling's Approximation\\n(Precision reaches 4 when n={})\".format(n_val))\n",
    "    plt.plot(n_values, relative_errors, label='relative error')\n",
    "    plt.plot(n_values, precision_errors, '.', color='g', markersize='2', label='precision')\n",
    "    plt.xlabel('n')\n",
    "    plt.ylabel('relative error / precision')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(lower_bound=2, upper_bound=2000):\n",
    "    \"\"\"\n",
    "    compute the relative_error and precision error between Striling's apprximation\n",
    "    and log(n!) for all values of n in between lower_bound and upper_bound.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize values \n",
    "    n_values = numpy.arange(lower_bound, upper_bound)\n",
    "    relative_errors = []\n",
    "    precision_errors = []\n",
    "\n",
    "    for n in n_values:\n",
    "\n",
    "        # compute the true value and Stirling's approximatation value of log(n!)\n",
    "        f = log_n_factorial(n) # true_value\n",
    "        F = stirling_approximatation(n) # approximate_value\n",
    "\n",
    "        # compute and record relative error and precision error\n",
    "        _, r, p = errors(f,F)\n",
    "        relative_errors.append(r)\n",
    "        precision_errors.append(p)\n",
    "        \n",
    "    return relative_errors, precision_errors, n_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_n_value(precision_errors, n_values, target=4):\n",
    "    \"\"\"\n",
    "    compute the first value of n where precision_error reaches the value specified by target\n",
    "    \"\"\"\n",
    "    \n",
    "    first_idx_to_hit_target = numpy.where(numpy.array(precision_errors) == target)[0][0]\n",
    "    return  n_values[first_idx_to_hit_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6195fab472e4537966b7eba4a529a13b",
     "grade": true,
     "grade_id": "cell-a5639245c28a1642",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# get the relative error and precision between log(n!) and the\n",
    "# Stirling approximation for all values of n in n_values\n",
    "relative_errors, precision_errors, n_values = get_data()\n",
    "\n",
    "# locate the value of n where we first hit four values of precision\n",
    "n_val = locate_n_value(precision_errors, n_values)\n",
    "\n",
    "# plot the relative errors and precision errors for different values of n\n",
    "plot_approximation(n_values, relative_errors, precision_errors, n_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab8966bfa41224e3345e4cd4fcbf9749",
     "grade": true,
     "grade_id": "cell-dcc45d9028355b73",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27bfc8b15912bb6e1cdfa2dfd103ced4",
     "grade": false,
     "grade_id": "cell-6968179660613369",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "[4 pts] Given the Taylor polynomial expansions of two functions around $x=0$\n",
    "\n",
    "$$\\frac{1}{1-\\Delta x} = 1 + \\Delta x + \\Delta x^2 + \\Delta x^3 + O(\\Delta x^4)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\cosh \\Delta x = 1 + \\frac{\\Delta x^2}{2!} + \\frac{\\Delta x^4}{4!} + O(\\Delta x^6)$$\n",
    "\n",
    "calculate their sum and product as well as the order of approximation for the truncation error (i.e. determine the exponent that belongs in the $O$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77d458abae3cfa5157eca11bd346e444",
     "grade": true,
     "grade_id": "cell-8500724062567566",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$\n",
    "\\begin{align}\n",
    "    \\frac{1}{1- \\Delta x}\n",
    "    +\n",
    "    cosh( \\Delta x )\n",
    "    &=\n",
    "    2 + \\Delta x + 1.5 ( \\Delta x )^2 + (\\Delta x )^3 + O((\\Delta x)^4)\n",
    "    \\\\\n",
    "    \\frac{cosh( \\Delta x )}{1- \\Delta x}\n",
    "    &=\n",
    "    (1 + \\Delta x + (\\Delta x)^2 + (\\Delta x)^3)\n",
    "    (1 + \\frac{(\\Delta x)^2}{2!} + \\frac{(\\Delta x)^4}{4!}) \n",
    "    +\n",
    "    O((\\Delta x)^4)\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{3(\\Delta x)^3}{2} + \\frac{3(\\Delta x)^2}{2} + 1\n",
    "    +\n",
    "    O((\\Delta x)^4)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "The order of approximation for the truncation error is 4 for both the sum and the product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "237fcd7151c710b1c2fe86744794671b",
     "grade": false,
     "grade_id": "cell-5632471080286207",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 3:  The great Exp challenge...\n",
    "\n",
    "Here you will attempt to write a function to calculate $e^x$ using its Taylor polynomial approximation expanded around $x_0=0$\n",
    "\n",
    "$$e^x \\approx T_n(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots + \\frac{x^n}{n!}$$\n",
    "\n",
    "such that the relative error of $f=e^x$ and $F=T_n(x)$ is of order Machine epsilon ($\\epsilon_{machine}$) for  $x\\in[-50,50]$.  This problem is actually a bit of a stinker and takes a bit of thought (particularly for $x<0$).  But I'll work you through it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d16eac32cec2913a95095d153a7994b7",
     "grade": false,
     "grade_id": "cell-8186992197557199",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(a)** [4 pts] Assume $x> 0$ and show that the upper bound on the *relative error*  at term $n$ \n",
    "\n",
    "$$r_n = \\frac{|e^x - T_n(x)|}{|e^x|}$$\n",
    "\n",
    "is given by\n",
    "\n",
    "$$r_n \\leq \\left | \\frac{x^{n+1}}{(n + 1)!} \\right |$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c066945aa96e6e08fcb676cf3b3e08f3",
     "grade": true,
     "grade_id": "cell-2747685663052674",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Let the proof begin\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{|e^x - T_n(x)|}{|e^x|}\n",
    "    &=\n",
    "    \\frac{e^x - T_n(x)}{e^x} \n",
    "    && \\text{because x > 0}\n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{R_n(x)}{e^x} \n",
    "    && \\text{because } R_n(x) = f(x) - T_n(x) \n",
    "    \\\\\n",
    "    &=\n",
    "    \\frac{e^c x^{n+1}}{e^x (n+1)!} \n",
    "    && \\text{because } R_n(x) = \\frac{f^{(n+1)}(c)(x-x_0)^{n+1}}{(n+1)!} \n",
    "    = \\frac{e^c x^{n+1}}{(n+1)!}\n",
    "    \\text{ for } c \\in [x_0, x]\n",
    "    \\\\\n",
    "    & \\leq  \\frac{e^x x^{n+1}}{e^x (n+1)!} \n",
    "    && \\text{because } c \\in [x_0, x] \\implies x_0 \\leq c \\leq x \\implies e^{x_0} \\leq e^c \\leq e^x\n",
    "    \\\\\n",
    "    & \\leq \\frac{x^{n+1}}{(n+1)!}\n",
    "    \\\\\n",
    "    \\frac{|e^x - T_n(x)|}{|e^x|}\n",
    "    & \\leq | \\frac{x^{n+1}}{(n+1)!} |\n",
    "    && \\text{because } x > 0 \n",
    "    \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a252bb988e5ae52a24a2e87dfe820b2",
     "grade": false,
     "grade_id": "cell-4678254376542691",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(b)** [4 pts] Analytically show that for **large** $x\\gg1$ and $n$, $r_n \\leq \\epsilon_{\\text{machine}}$ implies that we need *approximately* $n > e \\cdot x$ terms in the series (where $e = \\text{exp}(1)$).\n",
    "\n",
    "*Hint* Use Stirling's approximation $log (n!) \\approx n~log~n - n$ (and then this problem is still a bit tricky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8152aede9f1e1f429a231ee2b82df69c",
     "grade": true,
     "grade_id": "cell-4305745011657702",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "    \\epsilon_{machine}\n",
    "    & \\geq \n",
    "    | \\frac{x^{n+1}}{(n+1)!} |\n",
    "    \\\\\n",
    "    \\epsilon_{machine}\n",
    "    & \\geq\n",
    "    \\frac{x^{n+1}}{(n+1)!} \n",
    "    && \\text{ because } x, n > 0\n",
    "    \\\\\n",
    "    \\epsilon_{machine} (n+1)!\n",
    "    & \\geq x^{n+1}\n",
    "    \\\\\n",
    "    log( \\epsilon_{machine} (n+1)!)\n",
    "    & \\geq log( x^{n+1} )\n",
    "    \\\\\n",
    "    log( \\epsilon_{machine}) + (n+1) log(n+1) - (n+1)\n",
    "    & \\geq (n+1) log(x)\n",
    "    && \\text{ by Stirling's approximation}\n",
    "    \\\\\n",
    "    \\frac{log( \\epsilon_{machine})}{n+1} + log(n+1) - 1\n",
    "    & \\geq log(x)\n",
    "    \\\\\n",
    "    log(n+1)\n",
    "    & \\geq 1 + log(x) - \\frac{log( \\epsilon_{machine})}{n+1}\n",
    "    \\\\\n",
    "    n + 1\n",
    "    & \\geq ex \\cdot e^{\\frac{log( \\epsilon_{machine})}{n+1}}\n",
    "    \\\\\n",
    "    n + 1\n",
    "    & \\geq ex \n",
    "    && \\text{because } \\epsilon_{machine} \\text{ is so small, } \n",
    "    n \\text{ is so big then } e^{\\frac{log( \\epsilon_{machine})}{n+1}} \\approx 1\n",
    "    \\\\\n",
    "    n \n",
    "    & \\geq ex - 1 \n",
    "    \\\\\n",
    "    n \n",
    "    & \\geq ex\n",
    "    && \\text{because x is so big, we can drop the 1}\n",
    "    \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9cef1843dc0ae1deb7e6dbe5f77c33c",
     "grade": false,
     "grade_id": "cell-8048500717179941",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(c)** [6 pts] Use this result to write a Python function that accurately approximates $e^x$ using $T_n(x)$ for scalar $x$ and returns both the estimate and the number of terms in the series.  Note that the testing tolerance will be $8 \\cdot \\epsilon_{\\text{machine}}$ over the range $x\\in[-50,50]$\n",
    "\n",
    "Make sure to document your code including expected inputs, outputs, and assumptions being made.\n",
    "\n",
    "Some Hints:\n",
    "* To make your life easier,  we will assume $x$ and $T_n(x)$ are just of type float (not arrays)\n",
    "* Think about how we evaluated polynomials efficiently in class\n",
    "* $T_n(x)$ for $x<0$ is a highly unstable alternating series with severe cancellation issues. However, there is a simple fix that will return accurate solutions independent of the sign of $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horner(poly, n, x):\n",
    " \n",
    "    result = poly[0] \n",
    "    for i in range(1, n):\n",
    "        result = result*x + poly[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80286c759520479af4ce906ac70f62e5",
     "grade": false,
     "grade_id": "cell-5914967225034965",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def Tn_exp(x):\n",
    "    \"\"\" approximate e^x with Taylor's series. Use horner's method and the fact \n",
    "    that e^x = 1/e^|x| for x < 0 to optimize performence. \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "\n",
    "    assert(isinstance(x,float))\n",
    "\n",
    "    # initial values\n",
    "    # I had the issue that when x was small, n would not be large enough so I\n",
    "    # created the threshold to garunetee that n will be large enough\n",
    "    threshold = 50 if numpy.abs(x) < 50 else numpy.abs(x)\n",
    "    MAX_N = int(numpy.ceil(numpy.exp(1) * threshold))\n",
    "    is_negative = x < 0\n",
    "    \n",
    "    if is_negative:\n",
    "        x = numpy.abs(x)\n",
    "     \n",
    "    coefficients = [1/factorial(n) for n in range(0, MAX_N)]\n",
    "    coefficients.reverse()\n",
    "    Tn = horner(coefficients, MAX_N, x)\n",
    "        \n",
    "    if is_negative:\n",
    "        Tn = 1 / Tn\n",
    "        \n",
    "    return Tn, MAX_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Feel free to test your code here and/or make a plot of errors\n",
    "\n",
    "# # initial values\n",
    "# x_values = numpy.arange(-50, 50)\n",
    "# relative_errors = []\n",
    "# precision_errors = []\n",
    "# eps = numpy.finfo(float).eps\n",
    "\n",
    "# for x in x_values:\n",
    "    \n",
    "#     F = Tn_exp(float(x))[0] # approximation\n",
    "#     f = numpy.exp(x) # true value\n",
    "    \n",
    "#     _, r, p = errors(f,F)\n",
    "#     relative_errors.append(r)\n",
    "#     precision_errors.append(p)\n",
    "    \n",
    "#     print('x={}\\te^x = {}\\te^x~{}\\tr={}'.format(x, f, F, r / eps))\n",
    "\n",
    "    \n",
    "# # plot the relative errors and precision errors for different values of n\n",
    "# plot_approximation(x_values, relative_errors, precision_errors, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab0f32ce185cc2c7955fb0d04d65f027",
     "grade": true,
     "grade_id": "cell-9688375319882602",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 4.252190255480811 eps_machine\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Testing Cell (do not copy)\n",
    "\n",
    "x = numpy.linspace(-50, 50, 101)\n",
    "eps = numpy.finfo(float).eps\n",
    "tolerance = 8 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b1d4a353e51fbba1658f5a6968d1b42",
     "grade": false,
     "grade_id": "cell-c154452f653c5adc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(d)** [4 pts] In ieee double precision,  the largest value of $x$ that has $e^x<$ `numpy.finfo(float).max` is about 709 (i.e. `numpy.log(numpy.finfo(float).max))`. \n",
    "\n",
    "* What is the relative error in units of machine epsilon for your routine and `f=numpy.exp(709)`\n",
    "* What is the relative error in units of machine epsilon for `F=numpy.exp(1)**709` and `f=numpy.exp(709)`\n",
    "\n",
    "Explain your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4503599627370496.000000 relative error in machine_epsilon between our Taylor series of e^709 and numpy's e^709\n",
      "170.070226 relative error in machine_epsilon between our Taylor series of e^709 and python's e^709\n"
     ]
    }
   ],
   "source": [
    "# initial values\n",
    "max_x = 709\n",
    "eps = numpy.finfo(float).eps\n",
    "\n",
    "\n",
    "# compute relative error in units of machine epsilon \n",
    "# for our Taylor series VS numpy\n",
    "Tn = Tn_exp(float(max_x))[0]\n",
    "ex = numpy.exp(max_x)\n",
    "r = numpy.abs(Tn - ex) / numpy.abs(ex)\n",
    "r_in_machine_epsilon = r / eps\n",
    "print(\"{:5f} relative error in machine_epsilon between our Taylor series of e^709 and numpy's e^709\".format(r_in_machine_epsilon))\n",
    "\n",
    "# compute relative error in units of machine epsilon\n",
    "# for our Taylor series VS python\n",
    "F = numpy.exp(1)**max_x\n",
    "f = numpy.exp(max_x)\n",
    "r = numpy.abs(f - F) / numpy.abs(f)\n",
    "r_in_machine_epsilon_2 = r / eps\n",
    "print(\"{:5f} relative error in machine_epsilon between our Taylor series of e^709 and python's e^709\".format(r_in_machine_epsilon_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5a47ab9f08e7fe4764609703387ef9d",
     "grade": true,
     "grade_id": "cell-26e754d164cf2a3a",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The relative error between our Taylor series approximation of $e^{709}$ and numpy's $e^{709}$ is $4503599627370496 \\epsilon_{machine}$ while the relative error between python's $e^{709}$ and numpy's $e^{709}$ is around $170 \\epsilon_{machine}$. Clearly, the python routine significantly outperforms our Taylor series routine. This likely comes from two places. First, the python routine may have some built in optimization which helps to make it faster than our Taylor series routine. Second, although we use Horner's method, we still have a bunch of multiplication errors that build up when computing the coeifficents of n! (convergence error). So as we compute n!, we can get errors from representing floats with finite precision, and issues that generally arise with multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ddafb7ce96253940253bdd63de4c5a3",
     "grade": false,
     "grade_id": "cell-aaa3ac7c64bd5868",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(e)**  **How low can you go?** [4 pts] Can you modify your routine for `Tn_exp(x)`) to approximate $e^x$ on the range $x\\in[-709, 709]$ to within 20 $\\epsilon_{machine}$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c184e65af5b8e5f46c673245638f9ef",
     "grade": false,
     "grade_id": "cell-28a21d2a7d0bda99",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def Tn_exp(x, tolerance=None):\n",
    "    \"\"\" approximate e^x with Taylor's series. Use horner's method and the fact \n",
    "    that e^x = 1/e^|x| for x < 0 to optimize performence. \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        x: float\n",
    "            scalar value to approximate exp(x)\n",
    "    \"\"\"\n",
    "\n",
    "    assert(isinstance(x,float))\n",
    "\n",
    "    # initial values\n",
    "    # I had the issue that when x was small, n would not be large enough so I\n",
    "    # created the threshold to garunetee that n will be large enough\n",
    "    threshold = 100 if numpy.abs(x) < 100 else numpy.abs(x)\n",
    "    MAX_N = int(numpy.ceil(numpy.exp(1) * threshold))\n",
    "    Tn = 1\n",
    "    is_negative = x < 0\n",
    "    \n",
    "    if is_negative:\n",
    "        x = numpy.abs(x)\n",
    "     \n",
    "    # define range\n",
    "    range_ = list(range(1, MAX_N))\n",
    "    range_.reverse()\n",
    "    \n",
    "    # use horner's method to compute taylor series\n",
    "    for n in range_:\n",
    "        Tn = 1 + x/n * Tn\n",
    "        \n",
    "    if is_negative:\n",
    "        Tn = 1 / Tn\n",
    "        \n",
    "    return Tn, MAX_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6011675fe1441e14f574073b0e66e871",
     "grade": true,
     "grade_id": "cell-96883753198883843",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxmimum relative error = 18.978686562895863 eps_machine\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "x = numpy.linspace(-709, 709, 101)\n",
    "tolerance = 20 * eps\n",
    "\n",
    "answer = numpy.zeros(x.shape)\n",
    "N = numpy.zeros(x.shape)\n",
    "for i,xi in enumerate(x):\n",
    "    answer[i], N[i] = Tn_exp(xi, tolerance=tolerance)\n",
    "r = numpy.abs(answer - numpy.exp(x)) / numpy.abs(numpy.exp(x))\n",
    "print('maxmimum relative error = {} eps_machine'.format(r.max()/eps))\n",
    "assert(numpy.all(r  < tolerance))\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a18929a8d1127d2e6e77c98b23fb7855",
     "grade": false,
     "grade_id": "cell-6605000347660435",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4\n",
    "\n",
    "Consider a computing system that uses deoxyribonucleic acid (DNA) to store information.  Given that DNA is formed from the 4 nucleobases adenine, cytosine, guanine, and thymine (uracil is only found in RNA) let us assume that our storage of numbers will be base 4.  Answer the following questions based on this assuming that we have $p=3$ for the mantissa and the exponent $E \\in [-3, 3]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47f4d67565808d7f75e55f0689f21dd6",
     "grade": false,
     "grade_id": "cell-9339658002746268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(a)** [4 pts] Calculate how many numbers can we represent with this system?  What are the underflow and overflow limits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0255974fb370e1c331638d41f074ddf",
     "grade": true,
     "grade_id": "cell-623b625975f5da41",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "We can represent $2 * 3 * 4 * 4 * 7 + 1 =673$ different numbers with this system.\n",
    "\n",
    "\n",
    "Underflow: $1.00 * 4^{-3}$ in base 4 is $1 * \\frac{1}{64}$ in base 10, equaling 0.015625, which with rounding is 0.016 in base 10.\n",
    "\n",
    "\n",
    "Oveflow: $3.33 * 4^{3}$ in base 4 is $ ( 3 + \\frac{3}{4} + \\frac{3}{16} ) * 64$ in base 10, equaling 252 in base 10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29c7fc5ca0808f62a6b35897f3fbbe87",
     "grade": false,
     "grade_id": "cell-9339658dsfsdf46268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(b)** [4pts] Graphically show how the numbers on the decimal real line are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b95cccb5e3723bc4ebd7a1a10500f39a",
     "grade": true,
     "grade_id": "cell-4c6d3ae47566d1f1",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "base = 4\n",
    "\n",
    "fig = plt.figure(figsize=(15.0,3.0))\n",
    "axes = fig.add_subplot(2, 1, 1)\n",
    "\n",
    "axes.plot(0.0, 0.0, '|', markersize=20)\n",
    "axes.set_title(\"Distribution of Values $[-252, 252]$\")\n",
    "axes.set_yticks([])\n",
    "axes.set_xlabel(\"x\")\n",
    "axes.set_ylabel(\"\")\n",
    "\n",
    "for exponent in range(-3, 3+1):\n",
    "    for d1 in range(1, 4):\n",
    "        for d2 in range(4):\n",
    "            for d3 in range(4):\n",
    "                val = d1 + d2 * base ** -1 + d3 * base ** -2\n",
    "                axes.plot( val * base**exponent, 0.0, 'r|', markersize=8)\n",
    "                axes.plot(-val * base**exponent, 0.0, 'r|', markersize=8)\n",
    "                \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fab0fc5f3065c300023b60719c30cb3b",
     "grade": false,
     "grade_id": "cell-93396552502746268",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(c)** [4 pts] How many more numbers can we store in $N$ base-pairs (base 4) versus $N$ bits (base 2) where the mantissa and exponent are the same relative length (e.g.  p=3, and $E\\in[-3,3]$ for both problems)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16825fa4b75b7fc34d854b1653fe64b8",
     "grade": true,
     "grade_id": "cell-6de5d8dbf91c5ff7",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Generally if $p \\geq 2$, then the number of different digits we have in a system with base $\\beta$, set of exponents $E$, and precision $p$ is $2 * (\\beta - 1) * \\beta^{p-1}* |E| + 1$. So with $p=3, E \\in [-3, 3]$, then we know in base 2 we have 57 possible different numbers and in base 4 we have 673 different numbers. So if we have N base-pairs and N bits, then we can represent $673N-57N=616N$ more numbers using base 4 than base 2.\n",
    "\n",
    "More generally, for base 4 ($\\beta=4$), the number of digits that we have $D_4$, is \n",
    "$$D_4 = 6 * 4^{p-1} |E| + 1$$\n",
    "and for base 2 ($\\beta = 2$), the number of digits that we have $D_2$, is\n",
    "$$ D_2 = 2 |E| + 1$$\n",
    "So if we have N numbers of base 4 and N numbers of base 2, then we can represent $N \\cdot D_4$ numbers with base 4 and $N \\cdot D_2$ numbers with base 2. The difference between these is:\n",
    "$$\n",
    "N D_4 - N D_2 = N(D_4 - D_2) = N (6 * 4^{p-1} |E| + 1 - 2 |E| - 1 ) = 2 N |E| (3 * 4^{p-1} - 1)\n",
    "$$\n",
    "so if we have n numbers, then we will be able to represent $2 N |E| (3 * 4^{p-1} - 1)$ more numbers in base 4 than in base 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
